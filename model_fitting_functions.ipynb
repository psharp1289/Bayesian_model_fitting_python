{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Bayesian model fitting via iterative sampling\n",
    "\n",
    "This algorithm iteratively computes model evidence via a sampling procedure. Each iteration of the loop a posterior sample for each subject is derived by weighting the distribution of parameters by their likelihood. These samples at the subject level are concatenated, and then hyperparameters are fit to these distributions. Model evidence at the group level is a sum of subject-level evidence (given that is in log space). Once model evidence (defined by iBIC) does not improve, the iterations terminate. \n",
    "\n",
    "(1) Sample from a prior distribution over $\\forall i$ paramters $\\theta_{i}$\n",
    "\n",
    "(2) Generate likelihoods $p(data|\\theta_i)$\n",
    "\n",
    "(3) Compute posterior distribution over parameters by $p(\\theta)\\cdot p(data|\\theta)$\n",
    "\n",
    "(4) Fit new hyperparameters to the posterior sample then go back to (1) unless iBIC hasn't improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class & requisite functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to sample parameters within a model\n",
    "def sample_parameters(distribution_type,hyperparameter_list,sample_size):\n",
    "    from numpy.random import beta,gamma,chisquare,normal,poisson,uniform,logistic,multinomial,binomial\n",
    "    counter=1\n",
    "    for num in hyperparameter_list:\n",
    "        exec(\"global hp_{}; hp_{}={}\".format(counter,counter,num))\n",
    "        counter+=1\n",
    "    exec(\"global sample; sample={}({},{},{})\".format(distribution_type,hp_1,hp_2,sample_size))\n",
    "    return sample\n",
    "    \n",
    "# MODEL CLASS: assumes a hierarchical model \n",
    "# population parameters and subject level parameters \n",
    "# are jointly fit\n",
    "\n",
    "#  The structure of the model class:\n",
    "#         GROUP LEVEL:\n",
    "#              Name - E.g., Standard Q Learning\n",
    "#              Sample Size - How many samples for each parameter\n",
    "#              Lik - Likelihood function\n",
    "#              iBIC - Total evidence accounting for model complexity\n",
    "#              Total_Evidence: Sum of Subject-Level Evidences (sum b/c in log-space)\n",
    "#              Parameters (entries below x #parameters):\n",
    "#                     Hyperparameters - e.g., [mu,sigma]\n",
    "#                     Distribution Type - e.g., Beta\n",
    "#                     Name - e.g., Lrate-Value\n",
    "#\n",
    "#        SUBJECT LEVEL: \n",
    "#           Evidence (i.e., log mean likelihood)\n",
    "#           Parameters (entries below x #parameters):       \n",
    "#                 posterior mean\n",
    "#                 credible interval (95%)\n",
    "#                 samples\n",
    "#                 num_good_samples (not non or inf samples)\n",
    "\n",
    "\n",
    "class model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name=0\n",
    "        self.num_subjects=0\n",
    "        self.params=self.groupParams()\n",
    "        self.subjfit=self.subjFit()\n",
    "        self.subj_level_info=self.subjFit.subjParams()\n",
    "        self.sample_size=0\n",
    "        self.model_evidence_group=0\n",
    "        self.bic=10**10 #arbitrarily high starting iBIC\n",
    "        self.lik_func=0 #likelihood function\n",
    "        \n",
    "    \n",
    "    class groupParams:\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.name='eta'\n",
    "            self.distribution='beta'\n",
    "            self.hyperparameters=[1,2]\n",
    "                            \n",
    "    class subjFit:\n",
    "        def __init__(self):\n",
    "            self.model_evidence_subject=0\n",
    "            self.subj_level_info=self.subjParams()\n",
    "            \n",
    "        class subjParams:\n",
    "            def __init__(self):\n",
    "                self.posterior_mean=0\n",
    "                self.credible_interval=0\n",
    "                self.samples=[]\n",
    "                self.num_good_samples=[] #not nan or inf\n",
    "            \n",
    "        \n",
    "\n",
    "def moodyRL(model,data):\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    sample_size=model.sample_size\n",
    "    \n",
    "    #initialize variables at zero\n",
    "    q_values=np.zeros((model.sample_size,2)) #initialize values for each sample, assumes 2 choices\n",
    "    lik=np.zeros((model.sample_size,1))\n",
    "    mood=np.zeros((model.sample_size,1))\n",
    "    \n",
    "    #retrieve samples of parameters from model \n",
    "    lr_mood=np.reshape(model.lr_mood.samples,(model.sample_size,1))\n",
    "    lr_val=np.reshape(model.lr_val.samples,(model.sample_size,1))\n",
    "    inv_temp=np.reshape(model.inv_temp.samples,(model.sample_size,1))\n",
    "    mood_bias=np.reshape(model.mood_bias.samples,(model.sample_size,1))\n",
    "    \n",
    "    #retrieve relevant data\n",
    "    choice=data.choice # data = pandas dataframe\n",
    "    outcome=data.outcome\n",
    "    \n",
    "    #calculate log likelihood by iterating over choice data\n",
    "    for index in range(len(choice)):\n",
    "        lik = np.add(lik, (np.subtract(np.multiply(inv_temp,np.reshape(q_values[:,choice[index]],(model.sample_size,1))),np.reshape(scipy.special.logsumexp(np.multiply(inv_temp,q_values),axis=1),(model.sample_size,1)))))\n",
    "        uf=np.tanh(mood); #nonlinear transformation of mood by sigmoid\n",
    "        perceived_r=np.add(outcome[index],np.multiply(mood_bias,uf))\n",
    "        pe = np.subtract(perceived_r,np.reshape(q_values[:,choice[index]],(model.sample_size,1)))\n",
    "        mood=np.add(np.multiply(mood,(1-lr_mood)),np.multiply(lr_mood,pe))\n",
    "        x = np.add(np.reshape(q_values[:,choice[index]],(model.sample_size,1)), np.multiply(lr_val,pe))   \n",
    "        q_values[:,choice[index]] = x.flatten()\n",
    "    return lik\n",
    "\n",
    "def std_RL(model,data):\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    sample_size=model.sample_size\n",
    "    \n",
    "    #initialize variables at zero\n",
    "    q_values=np.zeros((model.sample_size,2)) #initialize values for each sample, assumes 2 choices\n",
    "    lik=np.zeros((model.sample_size,1))\n",
    "    \n",
    "    #retrieve samples of parameters from model \n",
    "    lr_val=np.reshape(model.lr_val.samples,(model.sample_size,1))\n",
    "    inv_temp=np.reshape(model.inv_temp.samples,(model.sample_size,1))\n",
    "    \n",
    "    #retrieve relevant data\n",
    "    choice=data.choice # data = pandas dataframe\n",
    "    outcome=data.outcome\n",
    "    \n",
    "    #calculate log likelihood by iterating over choice data\n",
    "    for index in range(len(choice)):\n",
    "        lik = np.add(lik, (np.subtract(np.multiply(inv_temp,np.reshape(q_values[:,choice[index]],(model.sample_size,1))),np.reshape(scipy.special.logsumexp(np.multiply(inv_temp,q_values),axis=1),(model.sample_size,1)))))\n",
    "        pe = np.subtract(outcome[index],np.reshape(q_values[:,choice[index]],(model.sample_size,1)))\n",
    "        x = np.add(np.reshape(q_values[:,choice[index]],(model.sample_size,1)), np.multiply(lr_val,pe))   \n",
    "        q_values[:,choice[index]] = x.flatten()\n",
    "    return lik\n",
    "\n",
    "#retrieve list of parameters from model\n",
    "def get_parameters_for_model(model):\n",
    "    parameters=[]\n",
    "    for var in vars(model):\n",
    "        exec('global x; x={}.{}'.format(model.name,var))\n",
    "        if type(x)==model.groupParams:\n",
    "            if var!='params':\n",
    "                parameters.append(var)\n",
    "    return parameters\n",
    "\n",
    "def build_model(name,likelihood,group_parameters_info,number_subjects,sample_size):\n",
    "    #  INPUTS:\n",
    "    #     name = name of model\n",
    "    #     likelihood = likelihood function\n",
    "    #     group_parameter_info = *Python dictionary* \n",
    "    #       defining parameter names, distributions and hyperparameters\n",
    "    #       EXAMPLE: {'eta':['beta',[1,1]]}\n",
    "    #     sample_size = number of samples from prior over group parameters\n",
    "    \n",
    "    #  OUTPUTS:\n",
    "    #     model class (see above)\n",
    "    \n",
    "    exec('{}=model()'.format(name,name),globals())\n",
    "    exec('{}.name=\"{}\"'.format(name,name))\n",
    "    exec('{}.num_subjects={}'.format(name,number_subjects))\n",
    "    exec('{}.lik_func={}'.format(name,likelihood))\n",
    "    exec('{}.sample_size={}'.format(name,sample_size))\n",
    "    \n",
    "    #encode in model the number of subjects and parameters in one's data\n",
    "    for parameter in group_parameters_info:\n",
    "        exec('{}.{}={}.groupParams()'.format(name,parameter,name))\n",
    "        exec('{}.{}.name=\"{}\"'.format(name,parameter,parameter))\n",
    "        exec('{}.{}.distribution=\"{}\"'.format(name,parameter,group_parameters_info[parameter][0]))\n",
    "        exec('{}.{}.hyperparameters={}'.format(name,parameter,group_parameters_info[parameter][1]))\n",
    "        exec('{}.{}.sample_size={}'.format(name,parameter,sample_size))\n",
    "        exec('{}.{}.samples=sample_parameters(\"{}\",{},{})'.format(name,parameter,group_parameters_info[parameter][0],group_parameters_info[parameter][1],sample_size))\n",
    "\n",
    "    for sub in range(number_subjects):\n",
    "        exec('{}.subject{}={}.subjFit()'.format(name,sub,name))\n",
    "        for parameter in group_parameters_info:\n",
    "            exec('{}.subject{}.{}={}.subject{}.subjParams()'.format(name,sub,parameter,name,sub))\n",
    "\n",
    "def compute_new_samples(likelihood_vector,model,subject):\n",
    "    \n",
    "    # model name\n",
    "    model_name=model.name\n",
    "    \n",
    "    #find bad likelihoods\n",
    "    not_infs= ~np.isinf(likelihood_vector)\n",
    "    not_nans= ~np.isnan(likelihood_vector)\n",
    "    valid_parameter_indices=not_infs==not_nans #for retreiving valid parameters\n",
    "    \n",
    "    \n",
    "    # clean liklelihood vector \n",
    "    likelihood_vector_noinf=likelihood_vector[~np.isinf(likelihood_vector)] #remove negative infinity likelihoods\n",
    "    likelihood_vector_cleaned=likelihood_vector_noinf[~np.isnan(likelihood_vector_noinf)] #remove nan likelihoods\n",
    "    good_samples=len(likelihood_vector_cleaned) #number of usable samples\n",
    "    \n",
    "    # log mean likelihood\n",
    "    model_evidence=np.mean(likelihood_vector_cleaned)\n",
    "    exec('{}.subject{}.model_evidence_subject={}'.format(model_name,subject,model_evidence))\n",
    "    \n",
    "    \n",
    "    #derive likelihood based weights by dividing by total likelihood (subtract here due to log space)\n",
    "    weights=np.exp(likelihood_vector_cleaned) \n",
    "    \n",
    "    #get parameters for resampling\n",
    "    parameters=get_parameters_for_model(model)\n",
    "    for parameter in parameters:\n",
    "        exec('global parameter_samples; parameter_samples={}.{}.samples'.format(model_name,parameter))\n",
    "        parameter_samps=np.reshape(parameter_samples,(model.sample_size,1))\n",
    "        good_parameters=parameter_samps[valid_parameter_indices]\n",
    "        mean,ci,sample=compute_samples(good_parameters,weights)\n",
    "        exec('{}.subject{}.{}.posterior_mean={}'.format(model_name,subject,parameter,mean))\n",
    "        exec('{}.subject{}.{}.credible_interval={}'.format(model_name,subject,parameter,ci))\n",
    "        exec('{}.subject{}.{}.samples={}'.format(model_name,subject,parameter,sample))\n",
    "        exec('{}.subject{}.{}.num_good_samples={}'.format(model_name,subject,parameter,good_samples))\n",
    "\n",
    "\n",
    "def compute_samples(parameter_samples,weights):\n",
    "    weights=np.divide(weights,np.sum(weights))\n",
    "    df=pd.DataFrame()\n",
    "    df['weights']=weights\n",
    "    df['parameter_samples']=parameter_samples    \n",
    "    df.sort_values('parameter_samples') #sort both parameter samples and weights by order of weights\n",
    "    \n",
    "    #weighted sum of all parameters by likelihoods\n",
    "    val=np.sum(df['weights']*df['parameter_samples'])\n",
    "    cdf=df.weights.cumsum()\n",
    "    \n",
    "    #resample from posterior\n",
    "    samples=[]\n",
    "    for i in np.arange(0.0001,1,0.001):\n",
    "        j=next(x[0] for x in enumerate(cdf) if x[1] > i)   \n",
    "        samples.append(df['parameter_samples'][j])\n",
    "               \n",
    "    #find 5% HDI index\n",
    "    index_5=next(x[0] for x in enumerate(cdf) if x[1] > 0.0499999) \n",
    "        \n",
    "    #find 95% HDI index\n",
    "    index_95=next(x[0] for x in enumerate(cdf) if x[1] > 0.9499999) \n",
    "            \n",
    "    \n",
    "    ci_lower=df['parameter_samples'][index_5]\n",
    "    ci_higher=df['parameter_samples'][index_95]\n",
    "    ci=[ci_lower,ci_higher]\n",
    "    \n",
    "    return val,ci,samples\n",
    "\n",
    "def fit_hyperparameters(model):\n",
    "    from scipy.stats import beta,gamma,norm,poisson,uniform,logistic\n",
    "    parameters=get_parameters_for_model(model)\n",
    "    number_subjects=model.num_subjects\n",
    "    model_name=model.name\n",
    "    for parameter in parameters:\n",
    "        parameter_full_sample=[]\n",
    "        exec('global distribution; distribution={}.{}.distribution'.format(model_name,parameter))\n",
    "        for subject in range(number_subjects):\n",
    "            exec('parameter_full_sample.append({}.subject{}.{}.samples)'.format(model_name,subject,parameter))\n",
    "        exec('global hyperparameters; hyperparameters={}.fit(parameter_full_sample)'.format(distribution))\n",
    "        if distribution=='gamma':\n",
    "            h1=hyperparameters[0]\n",
    "            h2=hyperparameters[2]\n",
    "        else:\n",
    "            h1=hyperparameters[0]\n",
    "            h2=hyperparameters[1]\n",
    "        #record hyperparameters\n",
    "        exec('{}.{}.hyperparameters={}'.format(model_name,parameter,[h1,h2]))\n",
    "        #sample from hyperparameters\n",
    "        exec('{}.{}.samples=sample_parameters(\"{}\",{},{})'.format(model_name,parameter,distribution,[h1,h2],model.sample_size))\n",
    "\n",
    "def get_total_evidence(model):\n",
    "    number_subjects=model.num_subjects\n",
    "    model_name=model.name\n",
    "    group_model_evidence=0\n",
    "    for subject in range(number_subjects):\n",
    "        exec('global subjEvidence; subjEvidence={}.subject{}.model_evidence_subject'.format(model_name,subject))\n",
    "        group_model_evidence+=subjEvidence\n",
    "    return group_model_evidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create synthetic datasets for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "from random import shuffle\n",
    "subjects=2\n",
    "all_data=[]\n",
    "for subject in range(subjects):\n",
    "    exec('data_{}=pd.DataFrame()'.format(subject))\n",
    "    c=[1,1,1,1,0,0,0,0,1,0,1,1,0,1,0,0,1,1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,0,1]*2\n",
    "    shuffle(c) #so each simulated subject's choices are different\n",
    "    exec('data_{}[\"choice\"]=c'.format(subject))\n",
    "    exec('data_{}[\"outcome\"]=[1,0,1,1,1,0,0,0,0,0,1,1,1,1,1,0,1,1,1,0,0,0,1,1,0,0,0,1,1,1,1,0,0,1]*2'.format(subject))\n",
    "    exec('all_data.append(data_{})'.format(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models=[]\n",
    "\n",
    "#define the number of subjects, parameters, and hyperparameters (i.e., parameters for group prior)\n",
    "\n",
    "# Moody RL (Eldar & Niv, 2015)\n",
    "name_1='mood_model'\n",
    "number_subjects=2\n",
    "parameter_sample_size=10000\n",
    "group_parameters_info_mood={'inv_temp':['gamma',[1,1]],'lr_mood':['beta',[1,1]],'mood_bias':['gamma',[1,1]],\n",
    "                       'lr_val':['beta',[1,1]]} #name of parameters and hyperpriors\n",
    "likelihood='moodyRL'\n",
    "build_model(name_1,likelihood,group_parameters_info_mood,number_subjects,parameter_sample_size)\n",
    "all_models.append(mood_model)\n",
    "\n",
    "# Standard model-free Q-learner\n",
    "name_2='RL_model'\n",
    "group_parameters_info_RL={'inv_temp':['gamma',[1,1]],\n",
    "                            'lr_val':['beta',[1,1]]} \n",
    "likelihood='std_RL'\n",
    "build_model(name_2,likelihood,group_parameters_info_RL,number_subjects,parameter_sample_size)\n",
    "all_models.append(RL_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mood_model\n",
      "mood_model- iBIC old:224.8232214648391, new: 224.09638966495658\n",
      "\n",
      "mood_model- iBIC old:224.09638966495658, new: 222.50267593775905\n",
      "\n",
      "mood_model- iBIC old:222.50267593775905, new: 222.50267593775905\n",
      "\n",
      "RL_model\n",
      "RL_model- iBIC old:202.80299627195805, new: 202.80299627195805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#iterate over models\n",
    "for model in all_models:\n",
    "    print(model.name)\n",
    "    improvement=1 #arbitrary start to ensure while loop starts\n",
    "    \n",
    "    #keep sampling until no improvement in iBIC\n",
    "    while improvement>0:\n",
    "        \n",
    "        #store old_bic for comparison to new_bic\n",
    "        old_bic=model.bic\n",
    "\n",
    "        #generate log likelihood for each subject and compute new samples\n",
    "        for subject in range(number_subjects):\n",
    "            data=all_data[subject]\n",
    "            likelihood=model.lik_func(model,data)\n",
    "            compute_new_samples(likelihood,model,subject)\n",
    "\n",
    "        #fit new hyperparameters from full posterior\n",
    "        fit_hyperparameters(model)\n",
    "        \n",
    "        #Compute iBIC\n",
    "        parameters=get_parameters_for_model(model)\n",
    "        Nparams = 2*len(parameters)\n",
    "        Ndatapoints = float(model.num_subjects*len(data['choice'])) #total number of datapoints  \n",
    "        evidence = get_total_evidence(model) # total evidence\n",
    "        new_bic = -2.0*float(evidence) + Nparams*np.log(Ndatapoints) # Bayesian Information Criterion\n",
    "        improvement = old_bic - new_bic # compute improvement of fit\n",
    "        \n",
    "        #only retain evidence and BIC if they improve\n",
    "        if improvement > 0:\n",
    "            model.model_evidence_group=evidence\n",
    "            model.bic=new_bic\n",
    "        \n",
    "        #read out latest iteration\n",
    "        print('{}- iBIC old:{}, new: {}\\n'.format(model.name, old_bic, model.bic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-45.19826342005548"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check subject fits work\n",
    "mood_model.subject0.model_evidence_subject"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
